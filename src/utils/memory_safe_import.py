#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë©”ëª¨ë¦¬ ì•ˆì „ import ìœ í‹¸ (ìµœì†Œí™” ë²„ì „)
í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì§€ì—° ë¡œë“œ
"""

import sys
import gc

def check_available_memory(min_mb=800):
    """ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬ í™•ì¸"""
    try:
        import psutil
        available = psutil.virtual_memory().available / 1024 / 1024
        print("ğŸ“Š ë©”ëª¨ë¦¬: {:.0f}MB (í•„ìš”: {}MB)".format(available, min_mb), file=sys.stderr)
        
        if available < min_mb:
            raise MemoryError("ë©”ëª¨ë¦¬ ë¶€ì¡±")
        return available
    except ImportError:
        print("âš ï¸  psutil ì—†ìŒ, ë©”ëª¨ë¦¬ ì²´í¬ ìŠ¤í‚µ", file=sys.stderr)
        return 1000.0
    except Exception as e:
        print("âš ï¸  ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        return 1000.0

def pre_cleanup():
    """ë©”ëª¨ë¦¬ ì •ë¦¬"""
    try:
        gc.collect()
    except:
        pass

def aggressive_memory_cleanup():
    """ì ê·¹ì  ë©”ëª¨ë¦¬ ì •ë¦¬ (ëª¨ë¸ ìƒì„± ì „)"""
    print("ğŸ§¹ ì ê·¹ì  ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘...", file=sys.stderr)
    
    try:
        # 1ë‹¨ê³„: ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (ì—¬ëŸ¬ ë²ˆ)
        for i in range(3):
            gc.collect()
            print("  {}ë‹¨ê³„: gc.collect() ì™„ë£Œ".format(i+1), file=sys.stderr)
        
        # 2ë‹¨ê³„: ìºì‹œ ì •ë¦¬
        import torch
        if hasattr(torch, 'cuda') and torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("  CUDA ìºì‹œ ì •ë¦¬ ì™„ë£Œ", file=sys.stderr)
        
        # 3ë‹¨ê³„: numpy ìºì‹œ ì •ë¦¬
        try:
            import numpy as np
            if hasattr(np, 'seterr'):
                np.seterr(all='ignore')
            print("  numpy ì„¤ì • ì™„ë£Œ", file=sys.stderr)
        except:
            pass
        
        # 4ë‹¨ê³„: ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬ í™•ì¸
        try:
            import psutil
            available = psutil.virtual_memory().available / 1024 / 1024
            print("âœ… ì •ë¦¬ í›„ ë©”ëª¨ë¦¬: {:.0f}MB".format(available), file=sys.stderr)
        except:
            pass
            
    except Exception as e:
        print("âš ï¸  ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {}".format(e), file=sys.stderr)

def safe_model_instantiation(model_class, vocab_size, embed_dim, decoder_dim, attention_dim):
    """ì•ˆì „í•œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    print("ğŸ”§ ì•ˆì „í•œ ëª¨ë¸ ìƒì„±...", file=sys.stderr)
    
    try:
        # Step 1: ë©”ëª¨ë¦¬ ì •ë¦¬
        print("  1ï¸âƒ£  ë©”ëª¨ë¦¬ ì •ë¦¬...", file=sys.stderr)
        aggressive_memory_cleanup()
        
        # Step 2: ë©”ëª¨ë¦¬ ì¶©ë¶„ì„± í™•ì¸
        print("  2ï¸âƒ£  ë©”ëª¨ë¦¬ í™•ì¸...", file=sys.stderr)
        check_available_memory(min_mb=1200)
        
        # Step 3: PyTorch ë©”ëª¨ë¦¬ ì„¤ì •
        print("  3ï¸âƒ£  PyTorch ìµœì í™”...", file=sys.stderr)
        import torch
        torch.no_grad().__enter__()  # no_grad ëª¨ë“œ ì§„ì…
        
        # Step 4: ëª¨ë¸ ìƒì„± (ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì†Œí™”)
        print("  4ï¸âƒ£  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...", file=sys.stderr)
        model = model_class(
            vocab_size=vocab_size,
            embed_dim=embed_dim,
            decoder_dim=decoder_dim,
            attention_dim=attention_dim
        )
        print("     âœ… ìƒì„± ì™„ë£Œ", file=sys.stderr)
        
        # Step 5: ëª¨ë¸ì„ CPUë¡œ
        print("  5ï¸âƒ£  CPU ì „í™˜...", file=sys.stderr)
        model = model.cpu()
        model.eval()
        print("     âœ… ì„¤ì • ì™„ë£Œ", file=sys.stderr)
        
        # Step 6: ë©”ëª¨ë¦¬ ì •ë¦¬
        print("  6ï¸âƒ£  ë©”ëª¨ë¦¬ ì •ë¦¬...", file=sys.stderr)
        gc.collect()
        
        print("âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ", file=sys.stderr)
        return model
        
    except MemoryError as e:
        print("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±: {}".format(e), file=sys.stderr)
        raise
    except Exception as e:
        print("âŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        raise

def lazy_load_model_class():
    """MobileNetCaptioningModel ì§€ì—° ë¡œë“œ"""
    try:
        # ë©”ëª¨ë¦¬ í™•ì¸
        check_available_memory(min_mb=1000)
        
        # ì •ë¦¬
        pre_cleanup()
        
        # Import
        print("ë¡œë“œ ì¤‘: MobileNetCaptioningModel", file=sys.stderr)
        from src.muti_modal_model.model import Model
        print("âœ… ë¡œë“œ ì™„ë£Œ", file=sys.stderr)
        return Model
        
    except MemoryError as e:
        print("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±", file=sys.stderr)
        raise
    except ImportError as e:
        print("âŒ Import ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        raise
    except Exception as e:
        print("âŒ ì˜¤ë¥˜: {}".format(e), file=sys.stderr)
        raise

def lazy_load_quantization():
    """apply_dynamic_quantization ì§€ì—° ë¡œë“œ"""
    try:
        # ë©”ëª¨ë¦¬ í™•ì¸
        check_available_memory(min_mb=500)
        
        # ì •ë¦¬
        pre_cleanup()
        
        # Import
        print("ë¡œë“œ ì¤‘: apply_dynamic_quantization", file=sys.stderr)
        from src.utils.quantization_utils import apply_dynamic_quantization
        print("âœ… ë¡œë“œ ì™„ë£Œ", file=sys.stderr)
        return apply_dynamic_quantization
        
    except MemoryError as e:
        print("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±", file=sys.stderr)
        raise
    except ImportError as e:
        print("âŒ Import ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        raise
    except Exception as e:
        print("âŒ ì˜¤ë¥˜: {}".format(e), file=sys.stderr)
        raise

# ê°„í¸ í•¨ìˆ˜
def load_model_class():
    """ëª¨ë¸ í´ë˜ìŠ¤ ë¡œë“œ"""
    print('ëª¨ë¸ í´ë˜ìŠ¤ ë¡œë“œ ìš”ì²­ ë°›ìŒ', file=sys.stderr)
    return lazy_load_model_class()

def load_quantization_func():
    """ì–‘ìí™” í•¨ìˆ˜ ë¡œë“œ"""
    return lazy_load_quantization()


