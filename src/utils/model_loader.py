"""
ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
"""
import torch
import torch.nn as nn
import os
from .config import MODEL_PATH

# ëª¨ë¸ import
try:
    from src.muti_modal_model.model import MobileNetCaptioningModel
except ImportError:
    print("âš ï¸ ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    class MobileNetCaptioningModel(nn.Module):
        def __init__(self, vocab_size, embed_dim):
            super().__init__()
            self.emb = nn.Embedding(vocab_size, embed_dim)
            self.gru = nn.GRU(embed_dim, 512)
            self.fc = nn.Linear(512, vocab_size)
        def generate(self, img, wm, rwm, max_len):
            return ["<start>", "a", "test", "caption", "<end>"]

def load_base_model(model_path=None, device=None):
    """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
        device: torch device (Noneì´ë©´ CPU ì‚¬ìš©)
    
    Returns:
        model, word_map, rev_word_map
    """
    if model_path is None:
        model_path = MODEL_PATH
    if device is None:
        device = torch.device("cpu")
    
    print("ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ
    if isinstance(checkpoint, dict):
        if 'model_state_dict' in checkpoint:
            model_state = checkpoint['model_state_dict']
            vocab_size = checkpoint.get('vocab_size', 1000)
            word_map = checkpoint.get('word_map', {})
            rev_word_map = checkpoint.get('rev_word_map', {})
        else:
            model_state = checkpoint
            vocab_size = 1000
            word_map = {}
            rev_word_map = {}
    else:
        model_state = checkpoint
        vocab_size = 1000
        word_map = {}
        rev_word_map = {}
    
    # ëª¨ë¸ ìƒì„±
    embed_dim = 300  # GloVe ì‚¬ìš© ì‹œ
    model = MobileNetCaptioningModel(vocab_size=vocab_size, embed_dim=embed_dim)
    model.load_state_dict(model_state)
    model.eval()
    model.to(device)
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Vocab Size: {vocab_size})")
    return model, word_map, rev_word_map

