#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jetson Nanoìš© ìµœëŒ€ ì•ˆì •ì„± ëª¨ë¸ ë¡œë”
ëª¨ë¸ ë¡œë“œ ë‹¨ê³„ë³„ ë””ë²„ê¹…
"""

import torch
import os
import gc
import sys

def safe_load_checkpoint(path):
    """ì•ˆì „í•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    print("  ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ...", file=sys.stderr)
    try:
        checkpoint = torch.load(path, map_location='cpu', weights_only=False)
        print("    âœ… ë¡œë“œ ì„±ê³µ", file=sys.stderr)
        return checkpoint
    except Exception as e:
        print("    âŒ ë¡œë“œ ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        return None

def safe_extract_metadata(checkpoint):
    """ì•ˆì „í•œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    print("  ë©”íƒ€ë°ì´í„° ì¶”ì¶œ...", file=sys.stderr)
    try:
        if not isinstance(checkpoint, dict):
            print("    âŒ checkpointê°€ dictê°€ ì•„ë‹˜", file=sys.stderr)
            return None
        
        if 'model_state_dict' not in checkpoint:
            print("    âŒ model_state_dict ì—†ìŒ", file=sys.stderr)
            return None
        
        word_map = checkpoint.get('word_map')
        rev_word_map = checkpoint.get('rev_word_map')
        vocab_size = checkpoint.get('vocab_size')
        
        if not (word_map and rev_word_map and vocab_size):
            print("    âŒ í•„ìˆ˜ ì •ë³´ ë¶€ì¡±", file=sys.stderr)
            return None
        
        state_dict = checkpoint['model_state_dict']
        decoder_dim = checkpoint.get('decoder_dim', 512)
        attention_dim = checkpoint.get('attention_dim', 256)
        
        metadata = {
            'word_map': word_map,
            'rev_word_map': rev_word_map,
            'vocab_size': vocab_size,
            'state_dict': state_dict,
            'decoder_dim': decoder_dim,
            'attention_dim': attention_dim
        }
        
        print("    âœ… ì¶”ì¶œ ì„±ê³µ (vocab={})".format(vocab_size), file=sys.stderr)
        return metadata
    except Exception as e:
        print("    âŒ ì¶”ì¶œ ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        return None

def safe_create_model(vocab_size, decoder_dim, attention_dim):
    """ì•ˆì „í•œ ëª¨ë¸ ìƒì„±"""
    print("  ëª¨ë¸ ìƒì„±...", file=sys.stderr)
    try:
        from src.muti_modal_model.model import MobileNetCaptioningModel
        
        model = MobileNetCaptioningModel(
            vocab_size=vocab_size,
            embed_dim=300,
            decoder_dim=decoder_dim,
            attention_dim=attention_dim
        )
        
        print("    âœ… ìƒì„± ì„±ê³µ", file=sys.stderr)
        return model
    except Exception as e:
        print("    âŒ ìƒì„± ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        return None

def safe_load_state_dict(model, state_dict):
    """ì•ˆì „í•œ ê°€ì¤‘ì¹˜ ë¡œë“œ"""
    print("  ê°€ì¤‘ì¹˜ ë¡œë“œ...", file=sys.stderr)
    try:
        model.load_state_dict(state_dict, strict=False)
        print("    âœ… ë¡œë“œ ì„±ê³µ", file=sys.stderr)
        return True
    except Exception as e:
        print("    âš ï¸  ë¡œë“œ ë¶€ë¶„ ì‹¤íŒ¨: {} (ê³„ì† ì§„í–‰)".format(e), file=sys.stderr)
        return False

def safe_setup_eval(model):
    """ì•ˆì „í•œ í‰ê°€ ëª¨ë“œ ì„¤ì •"""
    print("  í‰ê°€ ëª¨ë“œ ì„¤ì •...", file=sys.stderr)
    try:
        model = model.cpu()
        model.eval()
        print("    âœ… ì„¤ì • ì„±ê³µ", file=sys.stderr)
        return model
    except Exception as e:
        print("    âŒ ì„¤ì • ì‹¤íŒ¨: {}".format(e), file=sys.stderr)
        return None

def safe_cleanup(checkpoint=None, state_dict=None):
    """ì•ˆì „í•œ ë©”ëª¨ë¦¬ ì •ë¦¬"""
    print("  ë©”ëª¨ë¦¬ ì •ë¦¬...", file=sys.stderr)
    try:
        if checkpoint is not None:
            del checkpoint
        if state_dict is not None:
            del state_dict
        gc.collect()
        print("    âœ… ì •ë¦¬ ì„±ê³µ", file=sys.stderr)
    except:
        pass

def load_model_safe(path):
    """ì™„ë²½í•˜ê²Œ ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ"""
    print("\nğŸ“‚ ëª¨ë¸ ë¡œë“œ ì‹œì‘: {}".format(path), file=sys.stderr)
    
    if not os.path.exists(path):
        print("âŒ íŒŒì¼ ì—†ìŒ: {}".format(path))
        return None, None, None
    
    # Step 1: ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = safe_load_checkpoint(path)
    if checkpoint is None:
        return None, None, None
    
    # Step 2: ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    metadata = safe_extract_metadata(checkpoint)
    if metadata is None:
        safe_cleanup(checkpoint)
        return None, None, None
    
    # Step 3: ëª¨ë¸ ìƒì„±
    model = safe_create_model(
        metadata['vocab_size'],
        metadata['decoder_dim'],
        metadata['attention_dim']
    )
    if model is None:
        safe_cleanup(checkpoint, metadata['state_dict'])
        return None, None, None
    
    # Step 4: ê°€ì¤‘ì¹˜ ë¡œë“œ
    safe_load_state_dict(model, metadata['state_dict'])
    
    # Step 5: í‰ê°€ ëª¨ë“œ
    model = safe_setup_eval(model)
    if model is None:
        safe_cleanup(checkpoint, metadata['state_dict'])
        return None, None, None
    
    # Step 6: ë©”ëª¨ë¦¬ ì •ë¦¬
    safe_cleanup(checkpoint, metadata['state_dict'])
    
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    return model, metadata['word_map'], metadata['rev_word_map']

if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    print("\ní…ŒìŠ¤íŠ¸ ëª¨ë“œ:\n")
    
    model_path = 'models/lightweight_captioning_model.pth'
    if os.path.exists(model_path):
        model, word_map, rev_word_map = load_model_safe(model_path)
        if model:
            print("\nâœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        else:
            print("\nâŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
    else:
        print("ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {}".format(model_path))
