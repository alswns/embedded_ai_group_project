"""
Pruning ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
Magnitudeì™€ Structured pruningì´ ì œëŒ€ë¡œ ì ìš©ë˜ê³  ë¬¼ë¦¬ì ìœ¼ë¡œ ì§€ì›Œì¡ŒëŠ”ì§€ í™•ì¸
"""
import torch
import torch.nn as nn
from copy import deepcopy
import sys
import os

# ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.test_pruning import (
    apply_magnitude_pruning,
    apply_structured_pruning,
    count_parameters
)
from src.utils import load_base_model, setup_device

def verify_pruning(model, pruned_model, pruning_rate, method_name):
    """Pruningì´ ì œëŒ€ë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ ê²€ì¦"""
    print(f"\n{'='*70}")
    print(f"=== {method_name} ê²€ì¦ ===")
    print(f"{'='*70}")
    
    # 1. íŒŒë¼ë¯¸í„° ê°œìˆ˜ í™•ì¸
    old_params, old_trainable = count_parameters(model)
    new_params, new_trainable = count_parameters(pruned_model)
    reduction = (1 - new_params / old_params) * 100
    
    print(f"\nğŸ“Š íŒŒë¼ë¯¸í„° ê°œìˆ˜:")
    print(f"   ì›ë³¸: {old_params:,} íŒŒë¼ë¯¸í„°")
    print(f"   í”„ë£¨ë‹ í›„: {new_params:,} íŒŒë¼ë¯¸í„°")
    print(f"   ê°ì†Œìœ¨: {reduction:.2f}%")
    print(f"   ì˜ˆìƒ ê°ì†Œìœ¨: {pruning_rate*100:.0f}%")
    
    # 2. ë¬¼ë¦¬ì  êµ¬ì¡° í™•ì¸ (ë ˆì´ì–´ í¬ê¸°)
    print(f"\nğŸ” ë¬¼ë¦¬ì  êµ¬ì¡° í™•ì¸:")
    
    # Decoder êµ¬ì¡° í™•ì¸
    original_decoder = model.decoder
    pruned_decoder = pruned_model.decoder
    
    # decoder_dim í™•ì¸
    if hasattr(original_decoder, 'decoder_dim') and hasattr(pruned_decoder, 'decoder_dim'):
        orig_dim = original_decoder.decoder_dim
        pruned_dim = pruned_decoder.decoder_dim
        dim_reduction = (1 - pruned_dim / orig_dim) * 100
        print(f"   decoder_dim: {orig_dim} â†’ {pruned_dim} (ê°ì†Œ: {dim_reduction:.1f}%)")
    
    # attention_dim í™•ì¸
    if hasattr(original_decoder, 'attention_dim') and hasattr(pruned_decoder, 'attention_dim'):
        orig_att = original_decoder.attention_dim
        pruned_att = pruned_decoder.attention_dim
        att_reduction = (1 - pruned_att / orig_att) * 100
        print(f"   attention_dim: {orig_att} â†’ {pruned_att} (ê°ì†Œ: {att_reduction:.1f}%)")
    
    # 3. ë ˆì´ì–´ë³„ ê°€ì¤‘ì¹˜ í¬ê¸° í™•ì¸
    print(f"\nğŸ”¬ ë ˆì´ì–´ë³„ ê°€ì¤‘ì¹˜ í¬ê¸°:")
    
    layers_to_check = [
        ('decoder_att', 'decoder_att'),
        ('init_h', 'init_h'),
        ('fc', 'fc'),
        ('encoder_att', 'encoder_att'),
        ('decode_step', 'decode_step')
    ]
    
    for layer_name, attr_name in layers_to_check:
        if hasattr(original_decoder, attr_name) and hasattr(pruned_decoder, attr_name):
            orig_layer = getattr(original_decoder, attr_name)
            pruned_layer = getattr(pruned_decoder, attr_name)
            
            if isinstance(orig_layer, nn.Linear):
                orig_weight = orig_layer.weight.data
                pruned_weight = pruned_layer.weight.data
                print(f"   {layer_name}: {list(orig_weight.shape)} â†’ {list(pruned_weight.shape)}")
            elif isinstance(orig_layer, nn.GRUCell):
                orig_weight_ih = orig_layer.weight_ih.data
                orig_weight_hh = orig_layer.weight_hh.data
                pruned_weight_ih = pruned_layer.weight_ih.data
                pruned_weight_hh = pruned_layer.weight_hh.data
                print(f"   {layer_name}.weight_ih: {list(orig_weight_ih.shape)} â†’ {list(pruned_weight_ih.shape)}")
                print(f"   {layer_name}.weight_hh: {list(orig_weight_hh.shape)} â†’ {list(pruned_weight_hh.shape)}")
    
    # 4. ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    print(f"\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
    orig_size = sum(p.numel() * p.element_size() for p in model.parameters()) / 1024 / 1024
    pruned_size = sum(p.numel() * p.element_size() for p in pruned_model.parameters()) / 1024 / 1024
    size_reduction = (1 - pruned_size / orig_size) * 100
    print(f"   ì›ë³¸: {orig_size:.2f} MB")
    print(f"   í”„ë£¨ë‹ í›„: {pruned_size:.2f} MB")
    print(f"   ê°ì†Œìœ¨: {size_reduction:.2f}%")
    
    # 5. ê²€ì¦ ê²°ê³¼
    print(f"\nâœ… ê²€ì¦ ê²°ê³¼:")
    expected_reduction = pruning_rate * 100
    tolerance = 5.0  # 5% í—ˆìš© ì˜¤ì°¨
    
    if abs(reduction - expected_reduction) <= tolerance:
        print(f"   âœ… íŒŒë¼ë¯¸í„° ê°ì†Œìœ¨ì´ ì˜ˆìƒ ë²”ìœ„ ë‚´ì…ë‹ˆë‹¤ ({reduction:.1f}% â‰ˆ {expected_reduction:.0f}%)")
    else:
        print(f"   âš ï¸ íŒŒë¼ë¯¸í„° ê°ì†Œìœ¨ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤ ({reduction:.1f}% vs {expected_reduction:.0f}%)")
    
    if new_params < old_params:
        print(f"   âœ… ë¬¼ë¦¬ì  êµ¬ì¡° ë³€ê²½ í™•ì¸: íŒŒë¼ë¯¸í„°ê°€ ì‹¤ì œë¡œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤")
    else:
        print(f"   âŒ ë¬¼ë¦¬ì  êµ¬ì¡° ë³€ê²½ ì‹¤íŒ¨: íŒŒë¼ë¯¸í„°ê°€ ê°ì†Œí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    return {
        'old_params': old_params,
        'new_params': new_params,
        'reduction': reduction,
        'expected_reduction': expected_reduction,
        'physical_change': new_params < old_params
    }

def main():
    print("="*70)
    print("=== Pruning ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ===")
    print("="*70)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = setup_device()
    
    # ëª¨ë¸ ë¡œë“œ
    print("\nëª¨ë¸ ë¡œë“œ ì¤‘...")
    base_model, wm, rwm = load_base_model(device=device)
    base_model.eval()
    
    # ì›ë³¸ íŒŒë¼ë¯¸í„° í™•ì¸
    orig_params, _ = count_parameters(base_model)
    print(f"ì›ë³¸ ëª¨ë¸ íŒŒë¼ë¯¸í„°: {orig_params:,}")
    
    # í…ŒìŠ¤íŠ¸í•  í”„ë£¨ë‹ ë¹„ìœ¨
    pruning_rate = 0.3  # 30%
    
    # 1. Magnitude Pruning ê²€ì¦
    print("\n" + "="*70)
    print("Magnitude Pruning ì ìš© ì¤‘...")
    print("="*70)
    try:
        magnitude_model = apply_magnitude_pruning(base_model, pruning_rate)
        magnitude_model.eval()
        magnitude_result = verify_pruning(
            base_model, magnitude_model, pruning_rate, "Magnitude Pruning"
        )
    except Exception as e:
        print(f"âŒ Magnitude Pruning ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        magnitude_result = None
    
    # 2. Structured Pruning ê²€ì¦
    print("\n" + "="*70)
    print("Structured Pruning ì ìš© ì¤‘...")
    print("="*70)
    try:
        structured_model = apply_structured_pruning(base_model, pruning_rate)
        structured_model.eval()
        structured_result = verify_pruning(
            base_model, structured_model, pruning_rate, "Structured Pruning"
        )
    except Exception as e:
        print(f"âŒ Structured Pruning ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        structured_result = None
    
    # 3. ë¹„êµ ê²°ê³¼
    print("\n" + "="*70)
    print("=== ìµœì¢… ë¹„êµ ê²°ê³¼ ===")
    print("="*70)
    
    if magnitude_result and structured_result:
        print(f"\n{'í•­ëª©':<30} {'Magnitude':<20} {'Structured':<20}")
        print("-"*70)
        print(f"{'íŒŒë¼ë¯¸í„° ê°ì†Œìœ¨':<30} {magnitude_result['reduction']:<20.2f} {structured_result['reduction']:<20.2f}")
        print(f"{'ë¬¼ë¦¬ì  êµ¬ì¡° ë³€ê²½':<30} {'âœ…' if magnitude_result['physical_change'] else 'âŒ':<20} {'âœ…' if structured_result['physical_change'] else 'âŒ':<20}")
        
        # ì°¨ì´ì  í™•ì¸
        if abs(magnitude_result['reduction'] - structured_result['reduction']) < 1.0:
            print(f"\nâš ï¸ Magnitudeì™€ Structured Pruningì˜ ê²°ê³¼ê°€ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤.")
            print(f"   ì´ëŠ” ë‘ ë°©ë²•ì´ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print(f"\nâœ… Magnitudeì™€ Structured Pruningì˜ ì°¨ì´ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print("\n" + "="*70)
    print("ê²€ì¦ ì™„ë£Œ")
    print("="*70)

if __name__ == "__main__":
    main()

