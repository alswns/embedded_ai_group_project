#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jetson Nanoìš© ì•ˆì •í™”ëœ ì´ë¯¸ì§€ ìº¡ì…”ë‹
torchvision ì—†ì´ ìˆ˜ë™ ì´ë¯¸ì§€ ì²˜ë¦¬
"""

import cv2
import numpy as np
import os
import threading
import tempfile
import time
import psutil
import gc
import sys
import os 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
print("ğŸ“¦ ì•ˆì „ ëª¨ë“ˆ ë¡œë“œ...", file=sys.stderr)

# 1. í•„ìˆ˜ ëª¨ë“ˆë§Œ ë¡œë“œ
try:
    import torch
    print("âœ… torch ë¡œë“œ ì™„ë£Œ", file=sys.stderr)
except ImportError as e:
    print("âŒ PyTorch í•„ìš”: {}".format(e), file=sys.stderr)
    sys.exit(1)

# 2. PILë§Œ ë¡œë“œ (ë§¤ìš° ì•ˆì „)
try:
    from PIL import Image
    print("âœ… PIL ë¡œë“œ ì™„ë£Œ", file=sys.stderr)
except ImportError as e:
    print("âŒ Pillow í•„ìš”: {}".format(e), file=sys.stderr)
    sys.exit(1)

# 3. í”„ë¡œì íŠ¸ ëª¨ë“ˆ (torchvision ì—†ì´)
try:
    from src.utils.safe_model_loader import load_model_safe
    print("âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ", file=sys.stderr)
    from src.utils.quantization_utils import apply_dynamic_quantization
    print("âœ… quantization_utils ë¡œë“œ ì™„ë£Œ", file=sys.stderr)
    
except ImportError as e:
    print("âŒ í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì˜¤ë¥˜: {}".format(e), file=sys.stderr)
    sys.exit(1)

# ============================================================================
# í™˜ê²½ ì„¤ì • (CRITICAL)
# ============================================================================
print("âš™ï¸  í™˜ê²½ ì„¤ì •...", file=sys.stderr)

os.environ['CUDA_VISIBLE_DEVICES'] = ''
torch.backends.cudnn.enabled = False
torch.backends.cudnn.benchmark = False

torch.set_num_threads(2)
torch.set_num_interop_threads(1)

device = torch.device("cpu")
print("âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ (CPU ëª¨ë“œ)", file=sys.stderr)

# ============================================================================
# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (torchvision ëŒ€ì²´)
# ============================================================================

def preprocess_image(frame):
    """
    OpenCV BGR í”„ë ˆì„ì„ PyTorch í…ì„œë¡œ ë³€í™˜
    torchvisionì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    """
    # BGR â†’ RGB
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # PIL Imageë¡œ ë³€í™˜
    pil_image = Image.fromarray(rgb_frame)
    
    # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    pil_image = pil_image.resize((224, 224), Image.BILINEAR)
    
    # numpy arrayë¡œ ë³€í™˜
    image_array = np.array(pil_image, dtype=np.float32)
    
    # ì •ê·œí™” (ImageNet í‰ê· /í‘œì¤€í¸ì°¨)
    image_array = image_array / 255.0
    image_array -= np.array([0.485, 0.456, 0.406], dtype=np.float32)
    image_array /= np.array([0.229, 0.224, 0.225], dtype=np.float32)
    
    # CHW í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (H, W, C) â†’ (C, H, W)
    image_array = np.transpose(image_array, (2, 0, 1))
    
    # PyTorch í…ì„œë¡œ ë³€í™˜
    image_tensor = torch.from_numpy(image_array).float()
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    image_tensor = image_tensor.unsqueeze(0)
    
    return image_tensor

# ============================================================================
# ì„¤ì •
# ============================================================================

MODELS = {
    '1': {
        'name': 'Original Model',
        'path': 'models/lightweight_captioning_model.pth',
    },
    '2': {
        'name': 'Pruned Model',
        'path': 'pruning_results/Pruning_epoch_1_checkpoint.pt',
    }
}

QUANTIZE_OPTIONS = {
    '1': {'name': 'FP32 (ì›ë³¸)'},
    '2': {'name': 'FP16 (ë¯¸ì§€ì›)'},
    '3': {'name': 'INT8'}
}

# ============================================================================
# ìœ í‹¸ë¦¬í‹°
# ============================================================================

def select_model():
    """ëª¨ë¸ ì„ íƒ"""
    print("\nëª¨ë¸ ì„ íƒ:")
    for key, info in MODELS.items():
        exists = "âœ…" if os.path.exists(info['path']) else "âŒ"
        print("  {}. {} {}".format(key, info['name'], exists))
    
    while True:
        choice = input("ì„ íƒ (1-2): ").strip()
        if choice in MODELS:
            return choice
        print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")

def select_quantization():
    """ì–‘ìí™” ì„ íƒ"""
    print("\nì–‘ìí™” ì˜µì…˜:")
    for key, info in QUANTIZE_OPTIONS.items():
        print("  {}. {}".format(key, info['name']))
    
    while True:
        choice = input("ì„ íƒ (1-3): ").strip()
        if choice in QUANTIZE_OPTIONS:
            return choice
        print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")

def load_model(model_choice):
    """ëª¨ë¸ ë¡œë“œ (ì•ˆì „í•œ ë¡œë” ì‚¬ìš©)"""
    info = MODELS[model_choice]
    path = info['path']
    
    if not os.path.exists(path):
        print("âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {}".format(path))
        return None, None, None, None
    
    try:
        print("\nğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {}".format(path))
        model, word_map, rev_word_map = load_model_safe(path)
        
        if model is None:
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            return None, None, None, None
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return model, word_map, rev_word_map, info['name']
        
    except Exception as e:
        print("âŒ ì˜ˆìƒ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜: {}".format(e), file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        return None, None, None, None

def apply_quantization(model, choice):
    """ì–‘ìí™” ì ìš©"""
    try:
        if choice == '1':
            print("FP32 (ì–‘ìí™” ì—†ìŒ)")
        elif choice == '2':
            print("FP16ì€ CPUì—ì„œ ë¯¸ì§€ì› - FP32 ì‚¬ìš©")
        elif choice == '3':
            print("INT8 ì ìš©...")
            model = apply_dynamic_quantization(model)
    except Exception as e:
        print("âš ï¸  {}".format(e))
    
    model = model.cpu()
    model.eval()
    return model

def generate_caption(model, word_map, rev_word_map, frame):
    """ìº¡ì…˜ ìƒì„±"""
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (torchvision ëŒ€ì²´)
        image_tensor = preprocess_image(frame)
        
        # ìº¡ì…˜ ìƒì„±
        start = time.time()
        with torch.no_grad():
            generated = model.generate(image_tensor, word_map, rev_word_map, max_len=50)
        elapsed = (time.time() - start) * 1000
        
        caption = ' '.join([w for w in generated 
                           if w not in ['<start>', '<end>', '<pad>', '<unk>']])
        
        del image_tensor
        gc.collect()
        
        return caption, elapsed
    except Exception as e:
        print("âš ï¸  {}".format(e))
        gc.collect()
        return None, 0.0

# ============================================================================
# ë©”ì¸
# ============================================================================

def main():
    print("\n" + "="*70)
    print("ğŸ“¸ ì´ë¯¸ì§€ ìº¡ì…”ë‹ ì‹œìŠ¤í…œ")
    print("="*70)
    
    # ëª¨ë¸ ì„ íƒ
    model_choice = select_model()
    
    # ëª¨ë¸ ë¡œë“œ
    model, word_map, rev_word_map, model_name = load_model(model_choice)
    if model is None:
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # ì–‘ìí™” ì„ íƒ
    quant_choice = select_quantization()
    model = apply_quantization(model, quant_choice)
    
    print("\nëª¨ë¸: {}".format(model_name))
    print("="*70)
    print("\ní‚¤: s (ìº¡ì…˜), r (ì¬ìƒ), q (ì¢…ë£Œ)\n")
    
    # ì¹´ë©”ë¼
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ ì—†ìŒ")
        return
    
    last_caption = None
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            cv2.imshow('Captioning', frame)
            
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                break
            elif key == ord('s'):
                caption, elapsed = generate_caption(model, word_map, rev_word_map, frame)
                if caption:
                    last_caption = caption
                    print("\nğŸ“ {}".format(caption))
                    print("â±ï¸  {:.1f}ms\n".format(elapsed))
            elif key == ord('r') and last_caption:
                print("\nğŸ“ {}".format(last_caption))
    finally:
        cap.release()
        cv2.destroyAllWindows()
    
    print("ì¢…ë£Œ")

if __name__ == "__main__":
    main()
