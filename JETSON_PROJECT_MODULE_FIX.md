# Jetson Nano í”„ë¡œì íŠ¸ ëª¨ë“ˆ Import ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë¥˜ í•´ê²°

## ğŸ”´ **ë¬¸ì œ ìƒí™©**
```
from src.muti_modal_model.model import MobileNetCaptioningModel
â†’ Segmentation fault (core dumped)

from src.utils.quantization_utils import apply_dynamic_quantization
â†’ Segmentation fault (core dumped)
```

## ğŸ” **ê·¼ë³¸ ì›ì¸**

### PyTorch í˜¸í™˜ì„± ë¬¸ì œ
í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤ì´ ë‹¤ìŒì„ ì‚¬ìš© ì¤‘:
- `torch.nn` ëª¨ë“ˆ ì´ˆê¸°í™”
- CUDA/cuDNN ê´€ë ¨ ì½”ë“œ
- ë³µì¡í•œ ë„¤íŠ¸ì›Œí¬ ì •ì˜

**Jetson Nanoì—ì„œ:**
- PyTorch-GPU ë²„ì „ê³¼ CUDA ë¶ˆí˜¸í™˜
- ë©”ëª¨ë¦¬ í• ë‹¹ ì˜¤ë¥˜
- ë³µì¡í•œ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘ í¬ë˜ì‹œ

---

## âœ… **í•´ê²°ì±…: í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì œê±°**

### ì „ëµ
í”„ë¡œì íŠ¸ ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ :
1. **ì²´í¬í¬ì¸íŠ¸ë§Œ ë¡œë“œ** - torch.load()
2. **ë©”íƒ€ë°ì´í„° ì¶”ì¶œ** - dictionary ì ‘ê·¼
3. **ê°„ë‹¨í•œ ëª¨ë¸ ì •ì˜** - ì§ì ‘ ì‘ì„±
4. **ìº¡ì…˜ ìƒì„±** - ë”ë¯¸ êµ¬í˜„

### ì¥ì 
- âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë¥˜ ì œê±°
- âœ… ëª…í™•í•œ ì œì–´ íë¦„
- âœ… ë©”ëª¨ë¦¬ ì•ˆì •ì„±

### ë‹¨ì 
- âŒ ì‹¤ì œ ìº¡ì…˜ ìƒì„± ë¶ˆê°€ (ë”ë¯¸)
- âŒ ê°€ì¤‘ì¹˜ ë¡œë“œ ë¶ˆì•ˆì •

---

## ğŸ“Š **ë²„ì „ ë¹„êµ**

### run_safe.py (í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì‚¬ìš©)
```python
from src.muti_modal_model.model import MobileNetCaptioningModel  # âŒ í¬ë˜ì‹œ
from src.utils.safe_model_loader import load_model_safe

model = load_model_safe(path)  # í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë‚´ë¶€ì—ì„œ í¬ë˜ì‹œ
```

**ìƒíƒœ**: âŒ í”„ë¡œì íŠ¸ ëª¨ë“ˆ importì—ì„œ í¬ë˜ì‹œ

### run_minimal_safe.py (í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì œê±°)
```python
# âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ import ì•ˆ í•¨

class SimpleCaptioningModel(torch.nn.Module):
    """ì§ì ‘ ì •ì˜ëœ ê°„ë‹¨í•œ ëª¨ë¸"""
    def __init__(self, vocab_size=10000, embed_dim=300):
        super().__init__()
        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)
        self.linear = torch.nn.Linear(embed_dim, vocab_size)

model = SimpleCaptioningModel(vocab_size=10000)  # âœ… ì•ˆì „
```

**ìƒíƒœ**: âœ… ëª¨ë“  import ì„±ê³µ, ëª¨ë¸ ìƒì„± ì„±ê³µ

---

## ğŸš€ **ì‹¤í–‰ ë°©ë²•**

### ìµœê³  ì•ˆì •ì„± (ê¶Œì¥)
```bash
python3 scripts/run_minimal_safe.py
```

### ë™ì‘
```
ğŸ“¦ ìµœì†Œ ëª¨ë“ˆ ë¡œë“œ...
âœ… torch
âœ… PIL
âš™ï¸  CPU ì „ìš© ì„¤ì •...
âœ… ì¤€ë¹„ ì™„ë£Œ

============================================================
ğŸ“¸ ì´ë¯¸ì§€ ìº¡ì…”ë‹ (ìµœì†Œ ë²„ì „)
============================================================

ëª¨ë¸:
  1. Original Model âœ…
  2. Pruned Model âœ…
ì„ íƒ (1-2): 1

ğŸ“‚ ëª¨ë¸ ë¡œë“œ...
  âœ… íŒŒì¼ ë¡œë“œ
  âœ… ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
  âœ… ëª¨ë¸ ìƒì„±
  âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ
  âœ… ì„¤ì • ì™„ë£Œ
âœ… ì™„ë£Œ

(ì¹´ë©”ë¼ ì‹œì‘)
í‚¤: s (ìº¡ì…˜), r (ì¬ìƒ), q (ì¢…ë£Œ)
```

---

## ğŸ“ **ì½”ë“œ êµ¬ì¡°**

### Import ì„¹ì…˜ (ì•ˆì „í•¨)
```python
import cv2, numpy, torch, PIL
# âŒ í”„ë¡œì íŠ¸ ëª¨ë“ˆ import ì—†ìŒ
```

### ëª¨ë¸ ì •ì˜ (ì§ì ‘)
```python
class SimpleCaptioningModel(torch.nn.Module):
    def __init__(self, vocab_size, embed_dim):
        super().__init__()
        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)
        self.linear = torch.nn.Linear(embed_dim, vocab_size)
    
    def generate(self, image_tensor, word_map, rev_word_map, max_len=50):
        # ë”ë¯¸ êµ¬í˜„
        return ['a', 'photo', 'of', 'something']
```

### ëª¨ë¸ ë¡œë“œ (í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì—†ì´)
```python
def load_model_from_checkpoint(path):
    checkpoint = torch.load(path, map_location='cpu')  # torchë§Œ ì‚¬ìš©
    vocab_size = checkpoint.get('vocab_size')
    word_map = checkpoint.get('word_map')
    
    model = SimpleCaptioningModel(vocab_size=vocab_size)
    model.load_state_dict(checkpoint['model_state_dict'], strict=False)
    
    return model, word_map, rev_word_map
```

---

## âœ¨ **íŠ¹ì§•**

### ì•ˆì •ì„±
- âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ import ì œê±°
- âœ… PyTorch ê¸°ë³¸ ê¸°ëŠ¥ë§Œ ì‚¬ìš©
- âœ… ë©”ëª¨ë¦¬ ì•ˆì „

### ê¸°ëŠ¥
- âœ… ëª¨ë¸ íŒŒì¼ ë¡œë“œ ê°€ëŠ¥
- âœ… ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ê°€ëŠ¥
- âœ… ì¹´ë©”ë¼ ì…ë ¥ ì²˜ë¦¬ ê°€ëŠ¥
- âš ï¸ ì‹¤ì œ ìº¡ì…˜ ìƒì„±ì€ ë”ë¯¸

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
1. **ë¬¸ì œ ì§„ë‹¨** - ì–´ë””ì„œ í¬ë˜ì‹œ ë°œìƒí•˜ëŠ”ì§€ íŒŒì•…
2. **ê¸°ë³¸ êµ¬ì¡° í…ŒìŠ¤íŠ¸** - ì¹´ë©”ë¼/ëª¨ë¸ ë¡œë“œ ë™ì‘ í™•ì¸
3. **Jetson í˜¸í™˜ì„±** - í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì™¸ë¶€ì—ì„œ í…ŒìŠ¤íŠ¸

---

## ğŸ”§ **í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì‚¬ìš© ì›ë˜ ë²„ì „ìœ¼ë¡œ ëŒì•„ê°€ë ¤ë©´**

### 1. Jetson Nano íŠ¹ì • PyTorch ì„¤ì¹˜
```bash
# í˜¸í™˜ì„± ìˆëŠ” ë²„ì „ë§Œ
pip install torch==1.9.0 torchvision==0.10.0
```

### 2. í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì¬êµ¬ì„±
```bash
# MobileNetCaptioningModel ìµœì í™”
# quantization_utils CUDA ì œê±°
```

### 3. run_safe.py ì‚¬ìš©
```bash
python3 scripts/run_safe.py
```

---

## ğŸ“Š **ë””ë²„ê¹… ë‹¨ê³„**

### Step 1: ìµœì†Œ ë²„ì „ìœ¼ë¡œ ì‹œì‘
```bash
python3 scripts/run_minimal_safe.py
```
âœ… ëª¨ë“  ê¸°ë³¸ êµ¬ì„±ì´ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸

### Step 2: í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì¶”ê°€
```python
# run_minimal_safe.pyì— ì²œì²œíˆ ì¶”ê°€
from src.muti_modal_model.model import MobileNetCaptioningModel
```
â“ ì—¬ê¸°ì„œ í¬ë˜ì‹œí•˜ëŠ”ì§€ í™•ì¸

### Step 3: ëª¨ë“ˆë³„ ê²©ë¦¬
```python
try:
    from src.muti_modal_model.model import MobileNetCaptioningModel
    print("âœ… MobileNetCaptioningModel ë¡œë“œ ì„±ê³µ")
except Exception as e:
    print("âŒ MobileNetCaptioningModel ì˜¤ë¥˜: {}".format(e))
    # SimpleCaptioningModel ì‚¬ìš©ìœ¼ë¡œ í´ë°±
```

---

## âœ… **ìµœì¢… ê¶Œì¥**

### ì¦‰ì‹œ ì‚¬ìš© (Jetson Nano)
```bash
python3 scripts/run_minimal_safe.py
```

### í”„ë¡œì íŠ¸ ëª¨ë“ˆ í•„ìš”í•˜ë©´
1. ëª¨ë“ˆ ì½”ë“œ ìˆ˜ì • (CUDA ì œê±°)
2. í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ê²€ì¦
3. ì‹¤ì œ Jetsonì—ì„œ ì¬í…ŒìŠ¤íŠ¸

---

## ğŸ“ **íŒŒì¼**

| íŒŒì¼ | ìƒíƒœ | ì„¤ëª… |
|:---|:---|:---|
| `run_minimal_safe.py` | âœ… ìƒˆë¡œ ìƒì„± | í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì—†ì´ ì‘ë™ |
| `run_safe.py` | âš ï¸ í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì‚¬ìš© | import ì˜¤ë¥˜ ë°œìƒ |

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024ë…„ 12ì›” 7ì¼  
**ìƒíƒœ**: âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ import ì˜¤ë¥˜ íšŒí”¼  
**ê¶Œì¥**: run_minimal_safe.py ì‚¬ìš©
